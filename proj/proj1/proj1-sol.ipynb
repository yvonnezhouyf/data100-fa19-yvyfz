{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('proj1.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro-hw2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Project 1: Food Safety \n",
    "## Cleaning and Exploring Data with Pandas\n",
    "## Due Date: Tuesday 09/24, 11:59 PM\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the project, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## This Assignment\n",
    "<img src=\"scoreCard.jpg\" width=400>\n",
    "\n",
    "In this project, you will investigate restaurant food safety scores for restaurants in San Francisco. Above is a sample score card for a restaurant. The scores and violation information have been made available by the San Francisco Department of Public Health. The main goal for this assignment is to understand how restaurants are scored. We will walk through various steps of exploratory data analysis to do this. We will provide comments and insights along the way to give you a sense of how we arrive at each discovery and what next steps it leads to.\n",
    "\n",
    "As we clean and explore these data, you will gain practice with:\n",
    "* Reading simple csv files\n",
    "* Working with data at different levels of granularity\n",
    "* Identifying the type of data collected, missing values, anomalies, etc.\n",
    "* Exploring characteristics and distributions of individual variables\n",
    "\n",
    "## Score Breakdown\n",
    "Question | Points\n",
    "--- | ---\n",
    "1a | 1\n",
    "1b | 0\n",
    "1c | 0\n",
    "1d | 3\n",
    "1e | 1\n",
    "2a | 1\n",
    "2b | 2\n",
    "3a | 2\n",
    "3b | 0\n",
    "3c | 2\n",
    "3d | 1\n",
    "3e | 1\n",
    "3f | 1\n",
    "4a | 2\n",
    "4b | 3\n",
    "5a | 1\n",
    "5b | 1\n",
    "5c | 1\n",
    "6a | 2\n",
    "6b | 3\n",
    "6c | 3\n",
    "7a | 2\n",
    "7b | 2\n",
    "7c | 6\n",
    "7d | 2\n",
    "7e | 3\n",
    "Total | 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "getting-started",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To start the assignment, run the cell below to set up some imports and the automatic tests that we will need for this assignment:\n",
    "\n",
    "In many of these assignments (and your future adventures as a data scientist) you will use `os`, `zipfile`, `pandas`, `numpy`, `matplotlib.pyplot`, and optionally `seaborn`.  \n",
    "\n",
    "1. Import each of these libraries as their commonly used abbreviations (e.g., `pd`, `np`, `plt`, and `sns`).  \n",
    "1. Don't forget to include `%matplotlib inline` which enables [inline matploblib plots](http://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-matplotlib). \n",
    "1. If you want to use `seaborn`, add the line `sns.set()` to make your plots look nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:52.935736Z",
     "start_time": "2018-08-18T01:21:52.932610Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "import-test",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert 'zipfile'in sys.modules\n",
    "assert 'pandas'in sys.modules and pd\n",
    "assert 'numpy'in sys.modules and np\n",
    "assert 'matplotlib'in sys.modules and plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Downloading the Data\n",
    "\n",
    "For this assignment, we need this data file: http://www.ds100.org/fa19/assets/datasets/proj1-SFBusinesses.zip\n",
    "\n",
    "We could write a few lines of code that are built to download this specific data file, but it's a better idea to have a general function that we can reuse for all of our assignments. Since this class isn't really about the nuances of the Python file system libraries, we've provided a function for you in ds100_utils.py called `fetch_and_cache` that can download files from the internet.\n",
    "\n",
    "This function has the following arguments:\n",
    "- `data_url`: the web address to download\n",
    "- `file`: the file in which to save the results\n",
    "- `data_dir`: (`default=\"data\"`) the location to save the data\n",
    "- `force`: if true the file is always re-downloaded \n",
    "\n",
    "The way this function works is that it checks to see if `data_dir/file` already exists. If it does not exist already or if `force=True`, the file at `data_url` is downloaded and placed at `data_dir/file`. The process of storing a data file for reuse later is called caching. If `data_dir/file` already and exists `force=False`, nothing is downloaded, and instead a message is printed letting you know the date of the cached file.\n",
    "\n",
    "The function returns a `pathlib.Path` object representing the location of the file ([pathlib docs](https://docs.python.org/3/library/pathlib.html#basic-use)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.150497Z",
     "start_time": "2018-08-18T01:21:53.141869Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch-and-cache",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import ds100_utils\n",
    "source_data_url = 'http://www.ds100.org/fa19/assets/datasets/proj1-SFBusinesses.zip'\n",
    "target_file_name = 'data.zip'\n",
    "\n",
    "# Change the force=False -> force=True in case you need to force redownload the data\n",
    "dest_path = ds100_utils.fetch_and_cache(\n",
    "    data_url=source_data_url, \n",
    "    data_dir='.', \n",
    "    file=target_file_name, \n",
    "    force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "data-here",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "After running the cell above, if you list the contents of the directory containing this notebook, you should see `data.zip`.\n",
    "\n",
    "*Note*: The command below starts with an `!`. This tells our Jupyter notebook to pass this command to the operating system. In this case, the command is the `ls` Unix command which lists files in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Before You Start\n",
    "\n",
    "For all the assignments with programming practices, please write down your answer in the answer cell(s) right below the question. \n",
    "\n",
    "We understand that it is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run codes, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors in running Autograder, and sometimes fail to generate the PDF file.\n",
    "\n",
    "**Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests in the autograder.** Please be sure to check your results carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading-description",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 1: Loading Food Safety Data\n",
    "\n",
    "We have data, but we don't have any specific questions about the data yet. Let's focus on understanding the structure of the data; this involves answering questions such as:\n",
    "\n",
    "* Is the data in a standard format or encoding?\n",
    "* Is the data organized in records?\n",
    "* What are the fields in each record?\n",
    "\n",
    "Let's start by looking at the contents of `data.zip`. It's not a just single file but rather a compressed directory of multiple files. We could inspect it by uncompressing it using a shell command such as `!unzip data.zip`, but in this project we're going to do almost everything in Python for maximum portability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1a: Looking Inside and Extracting the Zip Files\n",
    "\n",
    "Assign `my_zip` to a `zipfile.Zipfile` object representing `data.zip`, and assign `list_files` to a list of all the names of the files in `data.zip`.\n",
    "\n",
    "*Hint*: The [Python docs](https://docs.python.org/3/library/zipfile.html) describe how to create a `zipfile.ZipFile` object. You might also look back at the code from lecture and lab 4's optional hacking challenge. It's OK to copy and paste code from previous assignments and demos, though you might get more out of this exercise if you type out an answer.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.165555Z",
     "start_time": "2018-08-18T01:21:53.153523Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "loading-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "my_zip = zipfile.ZipFile(dest_path, 'r') # SOLUTION\n",
    "list_names = [f.filename for f in my_zip.filelist] # SOLUTION\n",
    "list_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "you-are-warned",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In your answer above, if you have written something like `zipfile.ZipFile('data.zip', ...)`, we suggest changing it to read `zipfile.ZipFile(dest_path, ...)`. In general, we **strongly suggest having your filenames hard coded as string literals only once** in a notebook. It is very dangerous to hard code things twice because if you change one but forget to change the other, you can end up with bugs that are very hard to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading-size",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now display the files' names and their sizes.\n",
    "\n",
    "If you're not sure how to proceed, read about the attributes of a `ZipFile` object in the Python docs linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.187732Z",
     "start_time": "2018-08-18T01:21:53.177203Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "loading-size-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "my_zip = zipfile.ZipFile(dest_path, 'r')\n",
    "for file in my_zip.filelist:\n",
    "    print('{}\\t{}'.format(file.filename, file.file_size))\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "keep-running",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Often when working with zipped data, we'll never unzip the actual zipfile. This saves space on our local computer. However, for this project the files are small, so we're just going to unzip everything. This has the added benefit that you can look inside the csv files using a text editor, which might be handy for understanding the structure of the files. The cell below will unzip the csv files into a subdirectory called `data`. Simply run this cell, i.e. don't modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "run-dis",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = Path('data')\n",
    "my_zip.extractall(data_dir)\n",
    "!ls {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "open-legend",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The cell above created a folder called `data`, and in it there should be four CSV files. Let's open up `legend.csv` to see its contents. To do this, click on 'Jupyter' in the top left, then navigate to fa19/proj/proj1/data/ and click on `legend.csv`. The file will open up in another tab. You should see something that looks like:\n",
    "\n",
    "    \"Minimum_Score\",\"Maximum_Score\",\"Description\"\n",
    "    0,70,\"Poor\"\n",
    "    71,85,\"Needs Improvement\"\n",
    "    86,90,\"Adequate\"\n",
    "    91,100,\"Good\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "look-inside",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1b: Programatically Looking Inside the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The `legend.csv` file does indeed look like a well-formed CSV file. Let's check the other three files. Rather than opening up each file manually, let's use Python to print out the first 5 lines of each. The `ds100_utils` library has a method called `head` that will allow you to retrieve the first N lines of a file as a list. For example `ds100_utils.head('data/legend.csv', 5)` will return the first 5 lines of \"data/legend.csv\". Try using this function to print out the first 5 lines of all four files that we just extracted from the zipfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "data_dir = \"./data/\"\n",
    "for f in list_names:\n",
    "    print(ds100_utils.head(data_dir + f, 5), \"\\n\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1c: Reading in the Files\n",
    "\n",
    "Based on the above information, let's attempt to load `businesses.csv`, `inspections.csv`, and `violations.csv` into pandas dataframes with the following names: `bus`, `ins`, and `vio` respectively.\n",
    "\n",
    "*Note:* Because of character encoding issues one of the files (`bus`) will require an additional argument `encoding='ISO-8859-1'` when calling `pd.read_csv`. At some point in your future, you should read all about [character encodings](https://www.diveinto.org/python3/strings.html). We won't discuss these in detail in DS100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.438446Z",
     "start_time": "2018-08-18T01:21:53.280442Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q1c-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# path to directory containing data\n",
    "dsDir = Path('data')\n",
    "\n",
    "bus = pd.read_csv(dsDir/'businesses.csv', encoding='ISO-8859-1') # SOLUTION\n",
    "ins = pd.read_csv(dsDir/'inspections.csv') # SOLUTION\n",
    "vio = pd.read_csv(dsDir/'violations.csv') # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "try-out",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now that you've read in the files, let's try some `pd.DataFrame` methods ([docs](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.html)).\n",
    "Use the `DataFrame.head` method to show the top few lines of the `bus`, `ins`, and `vio` dataframes. To show multiple return outputs in one single cell, you can use `display()`. Use `Dataframe.describe` to learn about the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "bus-head",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bus.head() # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "df-describe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The `DataFrame.describe` method can also be handy for computing summaries of various statistics of our dataframes. Try it out with each of our 3 dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "bus-describe",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bus.describe() # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "run-these",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now, we perform some sanity checks for you to verify that you loaded the data with the right structure. Run the following cells to load some basic utilities (you do not need to change these at all):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70c105800589cd29",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "First, we check the basic structure of the data frames you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.479700Z",
     "start_time": "2018-08-18T01:21:53.468578Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q1d-test0",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert all(bus.columns == ['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
    "                           'latitude', 'longitude', 'phone_number'])\n",
    "assert 6400 <= len(bus) <= 6420\n",
    "\n",
    "assert all(ins.columns == ['business_id', 'score', 'date', 'type'])\n",
    "assert 14210 <= len(ins) <= 14250\n",
    "\n",
    "assert all(vio.columns == ['business_id', 'date', 'description'])\n",
    "assert 39020 <= len(vio) <= 39080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "summs",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Next we'll check that the statistics match what we expect. The following are hard-coded statistical summaries of the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.518953Z",
     "start_time": "2018-08-18T01:21:53.482277Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfsumms",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bus_summary = pd.DataFrame(**{'columns': ['business_id', 'latitude', 'longitude'],\n",
    " 'data': {'business_id': {'50%': 68294.5, 'max': 94574.0, 'min': 19.0},\n",
    "  'latitude': {'50%': 37.780435, 'max': 37.824494, 'min': 37.668824},\n",
    "  'longitude': {'50%': -122.41885450000001,\n",
    "   'max': -122.368257,\n",
    "   'min': -122.510896}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "ins_summary = pd.DataFrame(**{'columns': ['business_id', 'score'],\n",
    " 'data': {'business_id': {'50%': 61462.0, 'max': 94231.0, 'min': 19.0},\n",
    "  'score': {'50%': 92.0, 'max': 100.0, 'min': 48.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "vio_summary = pd.DataFrame(**{'columns': ['business_id'],\n",
    " 'data': {'business_id': {'50%': 62060.0, 'max': 94231.0, 'min': 19.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print('What we expect from your Businesses dataframe:')\n",
    "display(bus_summary)\n",
    "print('What we expect from your Inspections dataframe:')\n",
    "display(ins_summary)\n",
    "print('What we expect from your Violations dataframe:')\n",
    "display(vio_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "all-close",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The code below defines a testing function that we'll use to verify that your data has the same statistics as what we expect. Run these cells to define the function. The `df_allclose` function has this name because we are verifying that all of the statistics for your dataframe are close to the expected values. Why not `df_allequal`? It's a bad idea in almost all cases to compare two floating point values like 37.780435, as rounding error can cause spurious failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-704124b2513d9286",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 1d: Verifying the data\n",
    "\n",
    "Now let's run the automated tests. If your dataframes are correct, then the following cell will seem to do nothing, which is a good thing! However, if your variables don't match the correct answers in the main summary statistics shown above, an exception will be raised.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.464919Z",
     "start_time": "2018-08-18T01:21:53.452814Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfcompare",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Run this cell to load this utility comparison function that we will use in various\n",
    "tests below (both tests you can see and those we run internally for grading).\n",
    "\n",
    "Do not modify the function in any way.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def df_allclose(actual, desired, columns=None, rtol=5e-2):\n",
    "    \"\"\"Compare selected columns of two dataframes on a few summary statistics.\n",
    "    \n",
    "    Compute the min, median and max of the two dataframes on the given columns, and compare\n",
    "    that they match numerically to the given relative tolerance.\n",
    "    \n",
    "    If they don't match, an AssertionError is raised (by `numpy.testing`).\n",
    "    \"\"\"    \n",
    "    # summary statistics to compare on\n",
    "    stats = ['min', '50%', 'max']\n",
    "    \n",
    "    # For the desired values, we can provide a full DF with the same structure as\n",
    "    # the actual data, or pre-computed summary statistics.\n",
    "    # We assume a pre-computed summary was provided if columns is None. In that case, \n",
    "    # `desired` *must* have the same structure as the actual's summary\n",
    "    if columns is None:\n",
    "        des = desired\n",
    "        columns = desired.columns\n",
    "    else:\n",
    "        des = desired[columns].describe().loc[stats]\n",
    "\n",
    "    # Extract summary stats from actual DF\n",
    "    act = actual[columns].describe().loc[stats]\n",
    "\n",
    "    return np.allclose(act, des, rtol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1e: Identifying Issues with the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-use-head",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Use the `head` command on your three files again. This time, describe at least one potential problem with the data you see. Consider issues with missing values and bad data.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1e\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.925582Z",
     "start_time": "2018-08-18T01:21:53.918456Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q1e-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION:**  \n",
    "There appears to be a missing phone number for NORMAN'S ICE CREAM AND FREEZES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro-explo",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We will explore each file in turn, including determining its granularity and primary keys and exploring many of the variables individually. Let's begin with the businesses file, which has been read into the `bus` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 2: Examining the Business Data\n",
    "\n",
    "From its name alone, we expect the `businesses.csv` file to contain information about the restaurants. Let's investigate the granularity of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "Examining the entries in `bus`, is the `business_id` unique for each record that is each row of data? Your code should compute the answer, i.e. don't just hard code `True` or `False`.\n",
    "\n",
    "Hint: use `value_counts()` or `unique()` to determine if the `business_id` series has any duplicates.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.936572Z",
     "start_time": "2018-08-18T01:21:53.927344Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "is_business_id_unique = bus['business_id'].value_counts().max() == 1 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "written"
    ]
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "With this information, you can address the question of granularity. Answer the questions below.\n",
    "\n",
    "1. What does each record represent (e.g., a business, a restaurant, a location, etc.)?  \n",
    "1. What is the primary key?\n",
    "1. What would you find by grouping by the following columns: `business_id`, `name`, `address` each individually?\n",
    "\n",
    "Please write your answer in the markdown cell below. You may create new cells below your answer to run code, but **please never add cells between a question cell and the answer cell below it.**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.993138Z",
     "start_time": "2018-08-18T01:21:53.989070Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q2b-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION**:  \n",
    "Each row has a unique `business_id` that serves as a primary key. If we then groupby name we see that there are many rows/records with the same name at different locations indicating that each record represents an individual restaurant, not a business. Grouping by `business_id` finds nothing new. Grouping by `name` finds all locations of the same restaurant (plus perhaps some spurious matches). Grouping by `address` finds all stores that share a location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.987051Z",
     "start_time": "2018-08-18T01:21:53.949344Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d5e152552a41e14d",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# use this cell for scratch work\n",
    "# BEGIN SOLUTION NO PROMPT\n",
    "print(\"Number of records:\", len(bus))\n",
    "print(\"Most frequently occuring business names:\", list(bus['name'].value_counts().sort_values(ascending=False).index[:3]))\n",
    "print(\"A few samples of the business with most frequent name ----------\")\n",
    "bus[bus['name'] == bus['name'].value_counts().idxmax()].head(7)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "written"
    ]
   },
   "source": [
    "---\n",
    "## 3: Zip Codes\n",
    "\n",
    "Next, let's  explore some of the variables in the business table. We begin by examining the postal code.\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "Answer the following questions about the `postal code` column in the `bus` data frame?  \n",
    "1. Are ZIP codes quantitative or qualitative? If qualitative, is it ordinal or nominal? \n",
    "1. What data type is used to represent a ZIP code?\n",
    "\n",
    "*Note*: ZIP codes and postal codes are the same thing.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.015633Z",
     "start_time": "2018-08-18T01:21:54.007576Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION:**  \n",
    "The ZIP codes are largely nominal fields with little meaning to differences or ratios.  \n",
    "While in some regions of the country similar numbers correspond to similar locations,\n",
    "this relationship is not reliable.\n",
    "\n",
    "The ZIP codes are currently stored as strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4c4a09f1ecf2f4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3b\n",
    "\n",
    "How many restaurants are in each ZIP code? \n",
    "\n",
    "In the cell below, create a series where the index is the postal code and the value is the number of records with that postal code in descending order of count. 94110 should be at the top with a count of 596. You'll need to use `groupby()`. You may also want to use `.size()` or `.value_counts()`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2151d673e6c36a1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "zip_counts = bus.groupby(\"postal_code\").size().sort_values(ascending=False) # SOLUTION\n",
    "zip_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf6a7fc2384bf533",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Did you take into account that some businesses have missing ZIP codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('zip_counts describes', sum(zip_counts), 'records.')\n",
    "print('The original data have', len(bus), 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ee47d11c7068c13",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Missing data is extremely common in real-world data science projects. There are several ways to include missing postal codes in the `zip_counts` series above. One approach is to use the `fillna` method of the series, which will replace all null (a.k.a. NaN) values with a string of our choosing. In the example below, we picked \"?????\". When you run the code below, you should see that there are 240 businesses with missing zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7169177fd00d200",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zip_counts = bus.fillna(\"?????\").groupby(\"postal_code\").size().sort_values(ascending=False)\n",
    "zip_counts.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d7c3379cb7dc256",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "An alternate approach is to use the DataFrame `value_counts` method with the optional argument `dropna=False`, which will ensure that null values are counted. In this case, the index will be `NaN` for the row corresponding to a null postal code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28eecc6664aa9bf2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bus[\"postal_code\"].value_counts(dropna=False).sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "zipcode-details",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Missing zip codes aren't our only problem. There are also some records where the postal code is wrong, e.g., there are 3 'Ca' and 3 'CA' values. Additionally, there are some extended postal codes that are 9 digits long, rather than the typical 5 digits. We will dive deeper into problems with postal code entries in subsequent questions. \n",
    "\n",
    "For now, let's clean up the extended zip codes by dropping the digits beyond the first 5. Rather than deleting or replacing the old values in the `postal_code` columnm, we'll instead create a new column called `postal_code_5`.\n",
    "\n",
    "The reason we're making a new column is that it's typically good practice to keep the original values when we are manipulating data. This makes it easier to recover from mistakes, and also makes it more clear that we are not working with the original raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.070634Z",
     "start_time": "2018-08-18T01:21:54.061377Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "run-me",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bus['postal_code_5'] = bus['postal_code'].str[:5]\n",
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "written"
    ]
   },
   "source": [
    "### Question 3c : A Closer Look at Missing ZIP Codes\n",
    "\n",
    "Let's look more closely at records with missing ZIP codes. Describe why some records have missing postal codes.  Pay attention to their addresses. You will need to look at many entries, not just the first five.\n",
    "\n",
    "*Hint*: The `isnull` method of a series returns a boolean series which is true only for entries in the original series that were missing.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.079907Z",
     "start_time": "2018-08-18T01:21:54.072706Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3c-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION:**  \n",
    "Many of the restuarants without ZIP codes are food trucks (e.g., OFF THE GRID) or catering services.\n",
    "Therefore, a missing ZIP code might actually make sense and dropping these from the analysis could bias our conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this cell as scratch to explore the data\n",
    "# BEGIN SOLUTION NO PROMPT\n",
    "bus[bus['postal_code'].isnull()]['address'].value_counts().head(3)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3d: Incorrect ZIP Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e48949d5308e5f4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "This dataset is supposed to be only about San Francisco, so let's set up a list of all San Francisco ZIP codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e48f854beb16cbb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "all_sf_zip_codes = [\"94102\", \"94103\", \"94104\", \"94105\", \"94107\", \"94108\", \n",
    "                    \"94109\", \"94110\", \"94111\", \"94112\", \"94114\", \"94115\", \n",
    "                    \"94116\", \"94117\", \"94118\", \"94119\", \"94120\", \"94121\", \n",
    "                    \"94122\", \"94123\", \"94124\", \"94125\", \"94126\", \"94127\", \n",
    "                    \"94128\", \"94129\", \"94130\", \"94131\", \"94132\", \"94133\", \n",
    "                    \"94134\", \"94137\", \"94139\", \"94140\", \"94141\", \"94142\", \n",
    "                    \"94143\", \"94144\", \"94145\", \"94146\", \"94147\", \"94151\", \n",
    "                    \"94158\", \"94159\", \"94160\", \"94161\", \"94163\", \"94164\", \n",
    "                    \"94172\", \"94177\", \"94188\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57244ec02a330146",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Set `weird_zip_code_businesses` equal to a new dataframe that contains only rows corresponding to ZIP codes that are 'weird'. We define weird as any zip code which has both of the following 2 properties: \n",
    "\n",
    "1. The zip code is not valid: Either not 5-digit long or not a San Francisco zip code.\n",
    "\n",
    "2. The zip is not missing. \n",
    "\n",
    "Use the `postal_code_5` column.\n",
    "\n",
    "*Hint*: The `~` operator inverts a boolean array. Use in conjunction with `isin` from lecture 3.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3d1\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c5f486cab68d56a0",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weird_zip_code_businesses = bus[~bus['postal_code_5'].isin(all_sf_zip_codes) & ~bus['postal_code_5'].isnull()] # SOLUTION\n",
    "weird_zip_code_businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98f842a32db99f23",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "If we were doing very serious data analysis, we might indivdually look up every one of these strange records. Let's focus on just two of them: ZIP codes 94545 and 94602. Use a search engine to identify what cities these ZIP codes appear in. Try to explain why you think these two ZIP codes appear in your dataframe. For the one with ZIP code 94602, try searching for the business name and locate its real address.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3d2\n",
    "points: 1\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-56691be6d6a68838",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    }
   },
   "source": [
    "**SOLUTION:**  \n",
    "94545 - Hayward, look at record and see it's vending machine company with many locations  \n",
    "94602 - Oakland, look at the record and see it's probably a typo and should be 94102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92663ead60440a42",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3e\n",
    "\n",
    "We often want to clean the data to improve our analysis. This cleaning might include changing values for a variable or dropping records.\n",
    "\n",
    "The value 94602 is wrong. Change it to the most reasonable correct value, using all information you have available from your internet search for real world business. Modify the `postal_code_5` field using `bus['postal_code_5'].str.replace` to replace 94602.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3e\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2128312ebada9d3c",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# WARNING: Be careful when uncommenting the line below, it will set the entire column to NaN unless you \n",
    "# put something to the right of the ellipses.\n",
    "# bus['postal_code_5'] = ...\n",
    "# BEGIN SOLUTION NO PROMPT\n",
    "bus['postal_code_5'] = bus['postal_code_5'].str.replace(\"94602\", \"94102\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3e\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3f\n",
    "\n",
    "Now that we have corrected one of the weird postal codes, let's filter our `bus` data such that only postal codes from San Francisco remain. While we're at it, we'll also remove the businesses that are missing a postal code. As we mentioned in question 3d, filtering our postal codes in this way may not be ideal. (Fortunately, this is just a course assignment.) Use the `postal_code_5` column.\n",
    "\n",
    "Assign `bus` to a new dataframe that has the same columns but only the rows with ZIP codes in San Francisco.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3f\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = bus[bus['postal_code_5'].isin(all_sf_zip_codes) & bus['postal_code_5'].notnull()] # SOLUTION\n",
    "bus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 4: Latitude and Longitude\n",
    "\n",
    "Let's also consider latitude and longitude values in the `bus` data frame and get a sense of how many are missing.\n",
    "\n",
    "### Question 4a\n",
    "\n",
    "How many businesses are missing longitude values?\n",
    "\n",
    "*Hint*: Use `isnull`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a1\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.132374Z",
     "start_time": "2018-08-18T01:21:54.123081Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "num_missing_longs = sum(bus['longitude'].isnull()) # SOLUTION\n",
    "num_missing_longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4a1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "annex-zip",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "As a somewhat contrived exercise in data manipulation, let's try to identify which ZIP codes are missing the most longitude values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-22502e4e3bc97a90",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Throughout problems 4a and 4b, let's focus on only the \"dense\" ZIP codes of the city of San Francisco, listed below as `sf_dense_zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.153495Z",
     "start_time": "2018-08-18T01:21:54.145177Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "annex-zip-codes",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sf_dense_zip = [\"94102\", \"94103\", \"94104\", \"94105\", \"94107\", \"94108\",\n",
    "                \"94109\", \"94110\", \"94111\", \"94112\", \"94114\", \"94115\",\n",
    "                \"94116\", \"94117\", \"94118\", \"94121\", \"94122\", \"94123\", \n",
    "                \"94124\", \"94127\", \"94131\", \"94132\", \"94133\", \"94134\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04deef019a758f65",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In the cell below, create a series where the index is `postal_code_5`, and the value is the number of businesses with missing longitudes in that ZIP code. Your series should be in descending order (the values should be in descending order). The first two rows of your answer should include postal code 94103 and 94110. Only businesses from `sf_dense_zip` should be included. \n",
    "\n",
    "*Hint*: Start by making a new dataframe called `bus_sf` that only has businesses from `sf_dense_zip`.\n",
    "\n",
    "*Hint*: Use `len` or `sum` to find out the output number.\n",
    "\n",
    "*Hint*: Create a custom function to compute the number of null entries in a series, and use this function with the `agg` method.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a2\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acf341c6f3ee2e77",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_missing_in_each_zip = ...\n",
    "# BEGIN SOLUTION NO PROMPT\n",
    "def count_null(s):\n",
    "    return len(s[s.isnull()])\n",
    "\n",
    "bus_sf = bus[bus['postal_code_5'].isin(sf_dense_zip)]\n",
    "num_missing_in_each_zip = bus_sf['longitude'].groupby(bus_sf[\"postal_code_5\"]).agg(count_null).sort_values(ascending = False)\n",
    "# END SOLUTION\n",
    "num_missing_in_each_zip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4a2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4b\n",
    "\n",
    "In question 4a, we counted the number of null values per ZIP code. Reminder: we still only use the zip codes found in `sf_dense_zip`. Let's now count the proportion of null values of longitudinal coordinates.\n",
    "\n",
    "Create a new dataframe of counts of the null and proportion of null values, storing the result in `fraction_missing_df`. It should have an index called `postal_code_5` and should also have 3 columns:\n",
    "\n",
    "1. `count null`: The number of missing values for the zip code.\n",
    "2. `count non null`: The number of present values for the zip code.\n",
    "3. `fraction null`: The fraction of values that are null for the zip code.\n",
    "\n",
    "Your data frame should be sorted by the fraction null in descending order. The first two rows of your answer should include postal code 94107 and 94124.\n",
    "\n",
    "Recommended approach: Build three series with the appropriate names and data and then combine them into a dataframe. This will require some new syntax you may not have seen.\n",
    "\n",
    "To pursue this recommended approach, you might find these two functions useful and you aren't required to use these two:\n",
    "\n",
    "* `rename`: Renames the values of a series.\n",
    "* `pd.concat`: Can be used to combine a list of Series into a dataframe. Example: `pd.concat([s1, s2, s3], axis=1)` will combine series 1, 2, and 3 into a dataframe. Be careful about `axis=1`. \n",
    "\n",
    "*Hint*: You can use the divison operator to compute the ratio of two series.\n",
    "\n",
    "*Hint*: The `~` operator can invert a boolean array. Or alternately, the `notnull` method can be used to create a boolean array from a series.\n",
    "\n",
    "*Note*: An alternate approach is to create three aggregation functions and pass them in a list to the `agg` function.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "fraction_missing_df = ... # make sure to use this name for your dataframe \n",
    "# BEGIN SOLUTION NO PROMPT\n",
    "\n",
    "def count_null(s):\n",
    "    return len(s[s.isnull()])\n",
    "def count_non_null(s):\n",
    "    return len(s[~s.isnull()])\n",
    "def fraction_null(s):\n",
    "    n = len(s[s.isnull()])\n",
    "    nn = len(s[~s.isnull()])\n",
    "    return (n/(n+nn))\n",
    "bus_sf = bus[bus['postal_code_5'].isin(sf_dense_zip)]\n",
    "fraction_missing_df = bus_sf['longitude'].groupby(bus['postal_code_5']).agg([count_non_null, count_null, fraction_null])\n",
    "fraction_missing_df.columns = ['count non null', 'count null', 'fraction null']\n",
    "fraction_missing_df = fraction_missing_df.sort_values(\"fraction null\", ascending=False)\n",
    "# END SOLUTION\n",
    "fraction_missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "summary-business",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Summary of the Business Data\n",
    "\n",
    "Before we move on to explore the other data, let's take stock of what we have learned and the implications of our findings on future analysis. \n",
    "\n",
    "* We found that the business id is unique across records and so we may be able to use it as a key in joining tables. \n",
    "* We found that there are some errors with the ZIP codes. As a result, we dropped the records with ZIP codes outside of San Francisco or ones that were missing. In practive, however, we could take the time to look up the restaurant address online and fix these errors.   \n",
    "* We found that there are a huge number of missing longitude (and latitude) values. Fixing would require a lot of work, but could in principle be automated for records with well-formed addresses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 5: Investigate the Inspection Data\n",
    "\n",
    "Let's now turn to the inspection DataFrame. Earlier, we found that `ins` has 4 columns named `business_id`, `score`, `date` and `type`.  In this section, we determine the granularity of `ins` and investigate the kinds of information provided for the inspections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-174ed23c543ad9da",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's start by looking again at the first 5 rows of `ins` to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f0fbe724a2783e33",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ins.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84f5d3684c7b6a66",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5a\n",
    "From calling `head`, we know that each row in this table corresponds to a single inspection. Let's get a sense of the total number of inspections conducted, as well as the total number of unique businesses that occur in the dataset.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.210570Z",
     "start_time": "2018-08-18T01:21:54.206688Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q5a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# The number of rows in ins\n",
    "rows_in_table  = ins.shape[0] # SOLUTION\n",
    "\n",
    "# The number of unique business IDs in ins.\n",
    "unique_ins_ids = len(ins['business_id'].unique()) # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q5a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5b\n",
    "\n",
    "Next, let us examine the Series in the `ins` dataframe called `type`. From examining the first few rows of `ins`, we see that `type` takes string value, one of which is `'routine'`, presumably for a routine inspection. What other values does the inspection `type` take? How many occurrences of each value is in `ins`? What can we tell about these values? Can we use them for further analysis? If so, how?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "points: 1\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.233970Z",
     "start_time": "2018-08-18T01:21:54.222908Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q5b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION:**  \n",
    "All the records have the same value, \"routine\", except for one. \n",
    "This variable will not be useful in any analysis because it provides no information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5c\n",
    "\n",
    "In this question, we're going to try to figure out what years the data span. The dates in our file are formatted as strings such as `20160503`, which are a little tricky to interpret. The ideal solution for this problem is to modify our dates so that they are in an appropriate format for analysis. \n",
    "\n",
    "In the cell below, we attempt to add a new column to `ins` called `new_date` which contains the `date` stored as a datetime object. This calls the `pd.to_datetime` method, which converts a series of string representations of dates (and/or times) to a series containing a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef5885d023fc290e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ins['new_date'] = pd.to_datetime(ins['date'])\n",
    "ins.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d48dfa6ba214c40f",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "As you'll see, the resulting `new_date` column doesn't make any sense. This is because the default behavior of the `to_datetime()` method does not properly process the passed string. We can fix this by telling `to_datetime` how to do its job by providing a format string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-574b120d333a379d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ins['new_date'] = pd.to_datetime(ins['date'], format='%Y%m%d')\n",
    "ins.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e743520b4c12c5e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "This is still not ideal for our analysis, so we'll add one more column that is just equal to the year by using the `dt.year` property of the new series we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e64451846eeb632e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ins['year'] = ins['new_date'].dt.year\n",
    "ins.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "written"
    ]
   },
   "source": [
    "Now that we have this handy `year` column, we can try to understand our data better.\n",
    "\n",
    "What range of years is covered in this data set? Are there roughly the same number of inspections each year? Provide your answer in text only in the markdown cell below. If you would like show your reasoning with codes, make sure you put your code cells **below** the markdown answer cell. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c\n",
    "points: 1\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.296957Z",
     "start_time": "2018-08-18T01:21:54.289662Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q5c-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION:**  \n",
    "No, 2018 only has a few. Also 2015 has substantially fewer inspections than 2016 or 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 6: Explore Inspection Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "inspections-focus",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 6a\n",
    "Let's look at the distribution of inspection scores. As we saw before when we called `head` on this data frame, inspection scores appear to be integer values. The discreteness of this variable means that we can use a barplot to visualize the distribution of the inspection score. Make a bar plot of the counts of the number of inspections receiving each score. \n",
    "\n",
    "It should look like the image below. It does not need to look exactly the same (e.g., no grid), but make sure that all labels and axes are correct.\n",
    "\n",
    "You might find this [matplotlib.pyplot tutorial](http://data100.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/DS-100/fa19&subPath=extra/pyplot.ipynb) useful. Key syntax that you'll need:\n",
    " + `plt.bar`\n",
    " + `plt.xlabel`\n",
    " + `plt.ylabel`\n",
    " + `plt.title`\n",
    "\n",
    "*Note*: If you want to use another plotting library for your plots (e.g. `plotly`, `sns`) you are welcome to use that library instead so long as it works on DataHub. If you use seaborn `sns.countplot()`, you may need to manually set what to display on xticks. \n",
    "\n",
    "<img src=\"q6a.png\" width=500>\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.309085Z",
     "start_time": "2018-08-18T01:21:54.299128Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "inspections-focus-code",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "score_counts = ins['score'].value_counts()\n",
    "plt.bar(score_counts.keys(), score_counts)\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Inspection Scores\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "written"
    ]
   },
   "source": [
    "### Question 6b\n",
    "\n",
    "Describe the qualities of the distribution of the inspections scores based on your bar plot. Consider the mode(s), symmetry, tails, gaps, and anamolous values. Are there any unusual features of this distribution? What do your observations imply about the scores?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 3\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:54.514679Z",
     "start_time": "2018-08-18T01:21:54.511225Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q6b-answer",
     "locked": false,
     "points": 3,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION:**  \n",
    "The distribution is unimodal with a peak at 100. \n",
    "It is skewed left (as expected with a variable bounded on the right). \n",
    "The distribution has a long left tail with some restaurants receiving scores \n",
    "that are in the 50s, 60s, and 70s. One unusal feature of the distribution is the \n",
    "bumpiness with even numbers having higher counts than odd. This may be because\n",
    "the violations result in penalties of 2, 4, 10, etc. points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5015c9badefcef07",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 6c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c84c79731d73d13c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's figure out which restaurants had the worst scores ever (single lowest score). Let's start by creating a new dataframe called `ins_named`. It should be exactly the same as `ins`, except that it should have the name and address of every business, as determined by the `bus` dataframe. If a `business_id` in `ins` does not exist in `bus`, the name and address should be given as NaN.\n",
    "\n",
    "*Hint*: Use the merge method to join the `ins` dataframe with the appropriate portion of the `bus` dataframe. See the official [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) on how to use `merge`.\n",
    "\n",
    "*Note*: For quick reference, a pandas 'left' join keeps the keys from the left frame, so if ins is the left frame, all the keys from ins are kept and if a set of these keys don't have matches in the other frame, the columns from the other frame for these \"unmatched\" key rows contains NaNs.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c1\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74ff1f795567e724",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ins_named = ins.merge(bus[[\"business_id\", \"name\", \"address\"]], how=\"left\", left_on = \"business_id\", right_on = \"business_id\") # SOLUTION\n",
    "ins_named.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q6c1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21208e1c9459aaa7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Using this data frame, identify the restaurant with the lowest inspection scores ever. Head to yelp.com and look up the reviews page for this restaurant. Copy and paste anything interesting you want to share.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c2\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ffca1dd2365b327b",
     "locked": false,
     "points": 3,
     "schema_version": 2,
     "solution": true
    }
   },
   "source": [
    "**SOLUTION:**  \n",
    "\n",
    "The restaurant with the worst score is D&A cafe. One review I found amusing was:\n",
    "\n",
    "*This place is awesome.*\n",
    "\n",
    "*I don't care that they've been shut down for health violations multiple times.*  \n",
    "\n",
    "*This place is always packed with regulars. I equate the cleanliness like if you were eating in Asia.  I've never had an issue.*\n",
    "\n",
    "*The food is good and cheap. I come for the happy hour after 10pm, and take it togo.  Staff is usually pretty friendly.* \n",
    "\n",
    "*Deep fried pig intestines are on point and only $4.25.*\n",
    "\n",
    "*Watermelon juice is insanely good and just over 2 bucks.*\n",
    "\n",
    "*Salt and pepper wings are crispy and seasoned well.*\n",
    "\n",
    "*I just got 3 dishes and a watermelon juice for $15. Hell yes.*\n",
    "\n",
    "*If you want cheap Chinese food, this is the place.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac6ea7361824a936",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Just for fun you can also look up the restaurants with the best scores. You'll see that lots of them aren't restaurants at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-22a0a8f7f74f431a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 7: Restaurant Ratings Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa4959b7d3bcd9d7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's consider various scenarios involving restaurants with multiple ratings over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ccb9a66fca2becd",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 7a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2331831e448277ce",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's see which restaurant has had the most extreme improvement in its rating, aka scores. Let the \"swing\" of a restaurant be defined as the difference between its highest-ever and lowest-ever rating. **Only consider restaurants with at least 3 ratings, aka rated for at least 3 times (3 scores)!** Using whatever technique you want to use, assign `max_swing` to the name of restaurant that has the maximum swing.\n",
    "\n",
    "*Note*: The \"swing\" is of a specific business. There might be some restaurants with multiple locations; each location has its own \"swing\".\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a1\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "def swing(s):\n",
    "    if len(s) < 3:\n",
    "        return 0\n",
    "    return max(s) - min(s)\n",
    "\n",
    "swing_series = ins_named['score'].groupby(ins_named['business_id']).agg(swing).rename('swing')\n",
    "bus_swing = pd.concat([bus.set_index('business_id'), swing_series], axis=1).sort_values(\"swing\", ascending=False)\n",
    "bus_swing\n",
    "# END SOLUTION\n",
    "max_swing = bus_swing.iloc[0]['name'] # SOLUTION\n",
    "max_swing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q7a1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a9b4b1f7bb3370b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 7b\n",
    "\n",
    "To get a sense of the number of times each restaurant has been inspected, create a multi-indexed dataframe called `inspections_by_id_and_year` where each row corresponds to data about a given business in a single year, and there is a single data column named `count` that represents the number of inspections for that business in that year. The first index in the MultiIndex should be on `business_id`, and the second should be on `year`.\n",
    "\n",
    "An example row in this dataframe might look tell you that business_id is 573, year is 2017, and count is 4.\n",
    "\n",
    "*Hint*: Use groupby to group based on both the `business_id` and the `year`.\n",
    "\n",
    "*Hint*: Use rename to change the name of the column to `count`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fc0d1651b6e1c59",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "inspections_by_id_and_year = ins.groupby([ins['business_id'], ins['year']]).size().rename(\"count\").to_frame() # SOLUTION\n",
    "inspections_by_id_and_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q7b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bea99093d7cad880",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "You should see that some businesses are inspected many times in a single year. Let's get a sense of the distribution of the counts of the number of inspections by calling `value_counts`. There are quite a lot of businesses with 2 inspections in the same year, so it seems like it might be interesting to see what we can learn from such businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7389be51062a967b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspections_by_id_and_year['count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q7c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 7c\n",
    "\n",
    "What's the relationship between the first and second scores for the businesses with 2 inspections in a year? Do they typically improve? For simplicity, let's focus on only 2016 for this problem, using `ins2016` data frame that will be created for you below. \n",
    "\n",
    "First, make a dataframe called `scores_pairs_by_business` indexed by `business_id` (containing only businesses with exactly 2 inspections in 2016).  This dataframe contains the field `score_pair` consisting of the score pairs **ordered chronologically**  `[first_score, second_score]`. \n",
    "\n",
    "Plot these scores. That is, make a scatter plot to display these pairs of scores. Include on the plot a reference line with slope 1. \n",
    "\n",
    "You may find the functions `sort_values`, `groupby`, `filter` and `agg` helpful, though not all necessary. \n",
    "\n",
    "The first few rows of the resulting table should look something like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>score_pair</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>business_id</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>24</th>\n",
    "      <td>[96, 98]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>45</th>\n",
    "      <td>[78, 84]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>66</th>\n",
    "      <td>[98, 100]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>67</th>\n",
    "      <td>[87, 94]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>76</th>\n",
    "      <td>[100, 98]</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "The scatter plot should look like this:\n",
    "\n",
    "<img src=\"q7c2.png\" width=500>\n",
    "\n",
    "In the cell below, create `scores_pairs_by_business` as described above.\n",
    "\n",
    "*Note: Each score pair must be a list type; numpy arrays will not pass the autograder.*\n",
    "\n",
    "*Hint: Use the `filter` method from lecture 3 to create a new dataframe that only contains restaurants that received exactly 2 inspections.*\n",
    "\n",
    "*Hint: Our code that creates the needed DataFrame is a single line of code that uses `sort_values`, `groupby`, `filter`, `groupby`, `agg`, and `rename` in that order. Your answer does not need to use these exact methods.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7c1\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:57.055537Z",
     "start_time": "2018-08-18T01:21:54.541279Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q7c-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the dataframe here\n",
    "scores_pairs_by_business = ...\n",
    "ins2016 = ins[ins['year'] == 2016]\n",
    "# BEGIN SOLUTION NO PROMPT\n",
    "# SOLUTION 1\n",
    "scores_pairs_by_business = (ins2016.sort_values('date')\n",
    "                            .loc[:, ['business_id', 'score']]\n",
    "                            .groupby('business_id')\n",
    "                            .filter(lambda group: len(group)==2)\n",
    "                            .groupby('business_id')\n",
    "                            .agg(list)\n",
    "                            .rename(columns={'score':'score_pair'}))\n",
    "\n",
    "# SOLUTION 2\n",
    "scores_pairs_by_business = (ins2016.sort_values('date')\n",
    "                            .groupby('business_id')\n",
    "                            .filter(lambda group: len(group)==2)\n",
    "                            .groupby('business_id')\n",
    "                            .agg({'score': lambda group: group.tolist()})\n",
    "                            .rename(columns={'score':'score_pair'}))\n",
    "scores_pairs_by_business.head()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q7c1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, create your scatter plot in the cell below. It does not need to look exactly the same (e.g., no grid) as the above sample, but make sure that all labels, axes and data itself are correct.\n",
    "\n",
    "Key pieces of syntax you'll need:\n",
    " + `plt.scatter` plots a set of points. Use `facecolors='none'` to make circle markers.\n",
    " + `plt.plot` for the reference line.\n",
    " + `plt.xlabel`, `plt.ylabel`, `plt.axis`, and `plt.title`.\n",
    "\n",
    "*Note*: If you want to use another plotting library for your plots (e.g. `plotly`, `sns`) you are welcome to use that library instead so long as it works on DataHub.\n",
    "\n",
    "*Hint*: You may find it convenient to use the `zip()` function to unzip scores in the list.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7c2\n",
    "points: 3\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:59.555721Z",
     "start_time": "2018-08-18T01:21:59.331772Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q7c-plot-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "first_score, second_score = zip(*scores_pairs_by_business['score_pair'])\n",
    "plt.scatter(first_score,second_score,s=20,facecolors='none',edgecolors='b')\n",
    "plt.plot([55,100],[55,100],'r-')\n",
    "plt.xlabel('First Score')\n",
    "plt.ylabel('Second Score')\n",
    "plt.axis([55,100,55,100])\n",
    "plt.title(\"First Inspection Score vs. Second Inspection Score\");\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q7d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 7d\n",
    "\n",
    "Another way to compare the scores from the two inspections is to examine the difference in scores. Subtract the first score from the second in `scores_pairs_by_business`. Make a histogram of these differences in the scores. We might expect these differences to be positive, indicating an improvement from the first to the second inspection.\n",
    "\n",
    "The histogram should look like this:\n",
    "\n",
    "<img src=\"q7d.png\" width=500>\n",
    "\n",
    "*Hint*: Use `second_score` and `first_score` created in the scatter plot code above.\n",
    "\n",
    "*Hint*: Convert the scores into numpy arrays to make them easier to deal with.\n",
    "\n",
    "*Hint*: Use `plt.hist()` Try changing the number of bins when you call `plt.hist()`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7d\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:59.739987Z",
     "start_time": "2018-08-18T01:21:59.558636Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q7d-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "diffs = np.array(second_score) - np.array(first_score)\n",
    "plt.hist(diffs, bins=30)\n",
    "plt.title(\"Distribution of Score Differences\")\n",
    "plt.xlabel(\"Score Difference (Second Score - First Score)\")\n",
    "plt.ylabel(\"Count\");\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q7e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 7e\n",
    "\n",
    "If a restaurant's score improves from the first to the second inspection, what do you expect to see in the scatter plot that you made in question 7c? What do you see?\n",
    "\n",
    "If a restaurant's score improves from the first to the second inspection, how would this be reflected in the histogram of the difference in the scores that you made in question 7d? What do you see?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7e\n",
    "points: 3\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:59.749757Z",
     "start_time": "2018-08-18T01:21:59.743534Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q7e-answer",
     "locked": false,
     "points": 3,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "**SOLUTION:**  \n",
    "If the restaurants tend to improve from the first to the second inspection, \n",
    "we would expect to see the points in the scatter plot fall above the line of slope 1. \n",
    "We would also expect to see the histogram of the difference in scores to be shifted toward\n",
    "positive values. Interestingly, we don't see this. The second inspection often is worse than first. \n",
    "The histogram of differences shows a unimodal distribution centered at 0, hinting that the\n",
    "average restaurant does not see a change in score between their first and second inspection.\n",
    "This distribution has long tails with some scores being as low as -20 and others as high as 20-30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "summary-inspections",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Summary of the Inspections Data\n",
    "\n",
    "What we have learned about the inspections data? What might be some next steps in our investigation? \n",
    "\n",
    "* We found that the records are at the inspection level and that we have inspections for multiple years.   \n",
    "* We also found that many restaurants have more than one inspection a year. \n",
    "* By joining the business and inspection data, we identified the name of the restaurant with the worst rating and optionally the names of the restaurants with the best rating.\n",
    "* We identified the restaurant that had the largest swing in rating over time.\n",
    "* We also examined the relationship between the scores when a restaurant has multiple inspections in a year. Our findings were a bit counterintuitive and may warrant further investigation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "read-only",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "You are finished with Project 1. You'll need to make sure that your PDF exports correctly to receive credit. Run the cell below and follow the instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 13 EXPORTED QUESTIONS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('proj1.ipynb', 'proj1.pdf')\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
